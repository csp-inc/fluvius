{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e428c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Environment setup\n",
    "from pystac_client import Client\n",
    "import planetary_computer as pc\n",
    "import os\n",
    "\n",
    "# Set the environment variable PC_SDK_SUBSCRIPTION_KEY, or set it here.\n",
    "# The Hub sets PC_SDK_SUBSCRIPTION_KEY automatically.\n",
    "# pc.settings.set_subscription_key(<YOUR API Key>)\n",
    "env_vars = !cat /content/.env\n",
    "\n",
    "for var in env_vars:\n",
    "    key, value = var.split(' = ')\n",
    "    os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c0c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import pandas as pd\n",
    "storage_options={'account_name':os.environ['ACCOUNT_NAME'],\\\n",
    "                 'account_key':os.environ['BLOB_KEY']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd3c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('az', account_name=storage_options['account_name'], account_key=storage_options['account_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af26615",
   "metadata": {},
   "outputs": [],
   "source": [
    "containers= ['usgs-data', 'ana-data', 'itv-data']\n",
    "a = fs.ls(containers[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fc163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list0 = [a for a in fs.ls(f'{containers[0]}/stations/') if 'csv' in a]\n",
    "station_list1 = [a for a in fs.ls(f'{containers[1]}/stations/') if 'csv' in a]\n",
    "station_list2 = [a for a in fs.ls(f'{containers[2]}/stations/') if 'csv' in a]\n",
    "#so within these lists, we want to look at each and count the number of rows\n",
    "#note that we don't want images that are before 2016.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc105bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = []\n",
    "length = []\n",
    "dates = []\n",
    "'''\n",
    "for s in station_list0:\n",
    "    z = pd.read_csv(f\"az://{fs.ls(f'{s}/')[0]}\", storage_options=storage_options).dropna()\n",
    "    dates.append([z['Date-Time'].iloc[0],z['Date-Time'].iloc[-1]])\n",
    "    length.append(len(z))\n",
    "    station.append(s)\n",
    "    '''\n",
    "date_min = '2014-01-01'\n",
    "for s in station_list1:\n",
    "    z = pd.read_csv(f\"az://{fs.ls(f'{s}/')[0]}\", storage_options=storage_options).dropna().sort_values(by='Date-Time')\n",
    "    z = z[z['Date-Time']>date_min]\n",
    "    if len(z) >=1:\n",
    "        dates.append([z['Date-Time'].iloc[0],z['Date-Time'].iloc[-1]])\n",
    "        length.append(len(z))\n",
    "        station.append(s)\n",
    "for s in station_list2:\n",
    "    z = pd.read_csv(f\"az://{fs.ls(f'{s}/')[0]}\", storage_options=storage_options).dropna().sort_values(by='Date-Time')\n",
    "    z = z[z['Date-Time']>date_min]\n",
    "    if len(z) >=1:\n",
    "        dates.append([z['Date-Time'].iloc[0],z['Date-Time'].iloc[-1]])\n",
    "        length.append(len(z))\n",
    "        station.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2d75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame({'station':station, 'nrows':length, 'daterange':dates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30b452a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.sum(final.nrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff0888ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>nrows</th>\n",
       "      <th>daterange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ana-data/stations/21750000.csv</td>\n",
       "      <td>17</td>\n",
       "      <td>[2009-08-21 09:15:00, 2019-10-06 10:38:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ana-data/stations/22050001.csv</td>\n",
       "      <td>33</td>\n",
       "      <td>[2001-01-20 18:30:00, 2019-11-21 11:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ana-data/stations/22500000.csv</td>\n",
       "      <td>13</td>\n",
       "      <td>[2009-07-10 11:30:00, 2014-11-24 10:06:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ana-data/stations/22700000.csv</td>\n",
       "      <td>21</td>\n",
       "      <td>[2009-04-07 09:00:00, 2019-10-18 09:21:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ana-data/stations/22900000.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2009-03-10 10:00:00, 2019-10-23 09:28:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ana-data/stations/23100000.csv</td>\n",
       "      <td>17</td>\n",
       "      <td>[2009-09-26 14:30:00, 2018-10-15 10:50:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ana-data/stations/23230000.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2009-09-23 09:30:00, 2018-11-07 09:30:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ana-data/stations/23250000.csv</td>\n",
       "      <td>20</td>\n",
       "      <td>[2009-09-25 08:00:00, 2018-12-07 09:10:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ana-data/stations/23700000.csv</td>\n",
       "      <td>21</td>\n",
       "      <td>[2009-10-11 12:15:00, 2019-11-29 09:12:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ana-data/stations/25200000.csv</td>\n",
       "      <td>15</td>\n",
       "      <td>[2011-11-04 09:30:00, 2019-08-11 10:27:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ana-data/stations/26200000.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2009-08-29 09:45:00, 2019-11-28 10:46:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ana-data/stations/26300000.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2009-01-09 09:45:00, 2019-11-30 09:55:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ana-data/stations/26350000.csv</td>\n",
       "      <td>16</td>\n",
       "      <td>[2009-03-09 10:00:00, 2019-06-24 09:49:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ana-data/stations/26800000.csv</td>\n",
       "      <td>17</td>\n",
       "      <td>[2009-07-16 11:20:00, 2019-07-26 10:45:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ana-data/stations/27500000.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2009-09-14 10:40:00, 2018-07-19 11:30:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ana-data/stations/27550000.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2009-09-17 11:00:00, 2018-11-10 09:24:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ana-data/stations/28240000.csv</td>\n",
       "      <td>25</td>\n",
       "      <td>[2009-03-08 11:00:00, 2020-04-02 11:02:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ana-data/stations/28300000.csv</td>\n",
       "      <td>14</td>\n",
       "      <td>[2009-04-08 14:45:00, 2020-02-18 10:07:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ana-data/stations/28850000.csv</td>\n",
       "      <td>20</td>\n",
       "      <td>[2009-06-11 15:10:00, 2019-05-27 13:20:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ana-data/stations/29050000.csv</td>\n",
       "      <td>16</td>\n",
       "      <td>[2010-03-05 13:00:00, 2019-12-09 14:08:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ana-data/stations/29100000.csv</td>\n",
       "      <td>22</td>\n",
       "      <td>[2009-06-26 15:10:00, 2019-09-18 14:07:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ana-data/stations/29200000.csv</td>\n",
       "      <td>13</td>\n",
       "      <td>[2009-06-27 15:30:00, 2019-09-14 10:36:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>itv-data/stations/ITV1.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2015-03-24, 2019-06-26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>itv-data/stations/ITV10.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2015-03-24, 2019-06-25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>itv-data/stations/ITV11.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2015-03-27, 2019-08-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>itv-data/stations/ITV12.csv</td>\n",
       "      <td>16</td>\n",
       "      <td>[2015-09-20, 2019-11-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>itv-data/stations/ITV13.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2015-01-06, 2019-12-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>itv-data/stations/ITV14.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2015-01-06, 2019-12-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>itv-data/stations/ITV15.csv</td>\n",
       "      <td>17</td>\n",
       "      <td>[2015-05-31, 2019-12-04]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>itv-data/stations/ITV16.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2015-02-06, 2019-09-13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>itv-data/stations/ITV2.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2015-03-23, 2019-06-26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>itv-data/stations/ITV3.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2015-01-06, 2019-11-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>itv-data/stations/ITV4.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2015-03-25, 2019-06-27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>itv-data/stations/ITV5.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2015-03-26, 2019-10-04]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>itv-data/stations/ITV6.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2015-01-06, 2019-12-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>itv-data/stations/ITV7.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2015-03-28, 2019-10-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>itv-data/stations/ITV8.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>[2015-05-29, 2019-10-09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>itv-data/stations/ITV9.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>[2015-03-28, 2019-10-04]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           station  nrows  \\\n",
       "0   ana-data/stations/21750000.csv     17   \n",
       "1   ana-data/stations/22050001.csv     33   \n",
       "2   ana-data/stations/22500000.csv     13   \n",
       "3   ana-data/stations/22700000.csv     21   \n",
       "4   ana-data/stations/22900000.csv     19   \n",
       "5   ana-data/stations/23100000.csv     17   \n",
       "6   ana-data/stations/23230000.csv     19   \n",
       "7   ana-data/stations/23250000.csv     20   \n",
       "8   ana-data/stations/23700000.csv     21   \n",
       "9   ana-data/stations/25200000.csv     15   \n",
       "10  ana-data/stations/26200000.csv     18   \n",
       "11  ana-data/stations/26300000.csv     18   \n",
       "12  ana-data/stations/26350000.csv     16   \n",
       "13  ana-data/stations/26800000.csv     17   \n",
       "14  ana-data/stations/27500000.csv     18   \n",
       "15  ana-data/stations/27550000.csv     19   \n",
       "16  ana-data/stations/28240000.csv     25   \n",
       "17  ana-data/stations/28300000.csv     14   \n",
       "18  ana-data/stations/28850000.csv     20   \n",
       "19  ana-data/stations/29050000.csv     16   \n",
       "20  ana-data/stations/29100000.csv     22   \n",
       "21  ana-data/stations/29200000.csv     13   \n",
       "22      itv-data/stations/ITV1.csv     19   \n",
       "23     itv-data/stations/ITV10.csv     18   \n",
       "24     itv-data/stations/ITV11.csv     18   \n",
       "25     itv-data/stations/ITV12.csv     16   \n",
       "26     itv-data/stations/ITV13.csv     18   \n",
       "27     itv-data/stations/ITV14.csv     19   \n",
       "28     itv-data/stations/ITV15.csv     17   \n",
       "29     itv-data/stations/ITV16.csv     18   \n",
       "30      itv-data/stations/ITV2.csv     19   \n",
       "31      itv-data/stations/ITV3.csv     18   \n",
       "32      itv-data/stations/ITV4.csv     19   \n",
       "33      itv-data/stations/ITV5.csv     19   \n",
       "34      itv-data/stations/ITV6.csv     18   \n",
       "35      itv-data/stations/ITV7.csv     19   \n",
       "36      itv-data/stations/ITV8.csv     18   \n",
       "37      itv-data/stations/ITV9.csv     19   \n",
       "\n",
       "                                     daterange  \n",
       "0   [2009-08-21 09:15:00, 2019-10-06 10:38:00]  \n",
       "1   [2001-01-20 18:30:00, 2019-11-21 11:00:00]  \n",
       "2   [2009-07-10 11:30:00, 2014-11-24 10:06:00]  \n",
       "3   [2009-04-07 09:00:00, 2019-10-18 09:21:00]  \n",
       "4   [2009-03-10 10:00:00, 2019-10-23 09:28:00]  \n",
       "5   [2009-09-26 14:30:00, 2018-10-15 10:50:00]  \n",
       "6   [2009-09-23 09:30:00, 2018-11-07 09:30:00]  \n",
       "7   [2009-09-25 08:00:00, 2018-12-07 09:10:00]  \n",
       "8   [2009-10-11 12:15:00, 2019-11-29 09:12:00]  \n",
       "9   [2011-11-04 09:30:00, 2019-08-11 10:27:00]  \n",
       "10  [2009-08-29 09:45:00, 2019-11-28 10:46:00]  \n",
       "11  [2009-01-09 09:45:00, 2019-11-30 09:55:00]  \n",
       "12  [2009-03-09 10:00:00, 2019-06-24 09:49:00]  \n",
       "13  [2009-07-16 11:20:00, 2019-07-26 10:45:00]  \n",
       "14  [2009-09-14 10:40:00, 2018-07-19 11:30:00]  \n",
       "15  [2009-09-17 11:00:00, 2018-11-10 09:24:00]  \n",
       "16  [2009-03-08 11:00:00, 2020-04-02 11:02:00]  \n",
       "17  [2009-04-08 14:45:00, 2020-02-18 10:07:00]  \n",
       "18  [2009-06-11 15:10:00, 2019-05-27 13:20:00]  \n",
       "19  [2010-03-05 13:00:00, 2019-12-09 14:08:00]  \n",
       "20  [2009-06-26 15:10:00, 2019-09-18 14:07:00]  \n",
       "21  [2009-06-27 15:30:00, 2019-09-14 10:36:00]  \n",
       "22                    [2015-03-24, 2019-06-26]  \n",
       "23                    [2015-03-24, 2019-06-25]  \n",
       "24                    [2015-03-27, 2019-08-09]  \n",
       "25                    [2015-09-20, 2019-11-09]  \n",
       "26                    [2015-01-06, 2019-12-09]  \n",
       "27                    [2015-01-06, 2019-12-09]  \n",
       "28                    [2015-05-31, 2019-12-04]  \n",
       "29                    [2015-02-06, 2019-09-13]  \n",
       "30                    [2015-03-23, 2019-06-26]  \n",
       "31                    [2015-01-06, 2019-11-09]  \n",
       "32                    [2015-03-25, 2019-06-27]  \n",
       "33                    [2015-03-26, 2019-10-04]  \n",
       "34                    [2015-01-06, 2019-12-09]  \n",
       "35                    [2015-03-28, 2019-10-09]  \n",
       "36                    [2015-05-29, 2019-10-09]  \n",
       "37                    [2015-03-28, 2019-10-04]  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96e6c27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1270697"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(final.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#703 images from Brazil needed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
