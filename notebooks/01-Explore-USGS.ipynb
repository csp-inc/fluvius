{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23e6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70e7fa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 90.0.4430\n",
      "[WDM] - Get LATEST driver version for 90.0.4430\n",
      "[WDM] - Driver [/root/.wdm/drivers/chromedriver/linux64/90.0.4430.24/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_no</th>\n",
       "      <th>site_name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01472157</td>\n",
       "      <td>French Creek near Phoenixville, PA</td>\n",
       "      <td>40.1515</td>\n",
       "      <td>-75.6013</td>\n",
       "      <td>POINT (-75.60130 40.15150)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01478245</td>\n",
       "      <td>White Clay Creek near Strickersville, PA</td>\n",
       "      <td>39.7475</td>\n",
       "      <td>-75.7708</td>\n",
       "      <td>POINT (-75.77080 39.74750)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01480617</td>\n",
       "      <td>West Branch Brandywine Creek at Modena, PA</td>\n",
       "      <td>39.9618</td>\n",
       "      <td>-75.8013</td>\n",
       "      <td>POINT (-75.80130 39.96180)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01480870</td>\n",
       "      <td>East Branch Brandywine Creek below Downingtown...</td>\n",
       "      <td>39.9687</td>\n",
       "      <td>-75.6733</td>\n",
       "      <td>POINT (-75.67330 39.96870)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01481000</td>\n",
       "      <td>Brandywine Creek at Chadds Ford, PA</td>\n",
       "      <td>39.8698</td>\n",
       "      <td>-75.5933</td>\n",
       "      <td>POINT (-75.59330 39.86980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>393806095273700</td>\n",
       "      <td>Atchison County Lake near Horton, KS</td>\n",
       "      <td>39.6350</td>\n",
       "      <td>-95.4603</td>\n",
       "      <td>POINT (-95.46030 39.63500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>393817095260100</td>\n",
       "      <td>Clear Creek at Decator Road near Horton, KS</td>\n",
       "      <td>39.6381</td>\n",
       "      <td>-95.4336</td>\n",
       "      <td>POINT (-95.43360 39.63810)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>394126096073500</td>\n",
       "      <td>Black Vermillion River Tributary above Central...</td>\n",
       "      <td>39.6906</td>\n",
       "      <td>-96.1264</td>\n",
       "      <td>POINT (-96.12640 39.69060)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>394146096085500</td>\n",
       "      <td>Centralia Lake near Centralia, KS</td>\n",
       "      <td>39.6961</td>\n",
       "      <td>-96.1486</td>\n",
       "      <td>POINT (-96.14860 39.69610)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>394218096095000</td>\n",
       "      <td>Black Vermillion River Tributary below Central...</td>\n",
       "      <td>39.7050</td>\n",
       "      <td>-96.1639</td>\n",
       "      <td>POINT (-96.16390 39.70500)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             site_no                                          site_name  \\\n",
       "0           01472157                 French Creek near Phoenixville, PA   \n",
       "1           01478245           White Clay Creek near Strickersville, PA   \n",
       "2           01480617         West Branch Brandywine Creek at Modena, PA   \n",
       "3           01480870  East Branch Brandywine Creek below Downingtown...   \n",
       "4           01481000                Brandywine Creek at Chadds Ford, PA   \n",
       "..               ...                                                ...   \n",
       "160  393806095273700               Atchison County Lake near Horton, KS   \n",
       "161  393817095260100        Clear Creek at Decator Road near Horton, KS   \n",
       "162  394126096073500  Black Vermillion River Tributary above Central...   \n",
       "163  394146096085500                  Centralia Lake near Centralia, KS   \n",
       "164  394218096095000  Black Vermillion River Tributary below Central...   \n",
       "\n",
       "     Latitude  Longitude                    geometry  \n",
       "0     40.1515   -75.6013  POINT (-75.60130 40.15150)  \n",
       "1     39.7475   -75.7708  POINT (-75.77080 39.74750)  \n",
       "2     39.9618   -75.8013  POINT (-75.80130 39.96180)  \n",
       "3     39.9687   -75.6733  POINT (-75.67330 39.96870)  \n",
       "4     39.8698   -75.5933  POINT (-75.59330 39.86980)  \n",
       "..        ...        ...                         ...  \n",
       "160   39.6350   -95.4603  POINT (-95.46030 39.63500)  \n",
       "161   39.6381   -95.4336  POINT (-95.43360 39.63810)  \n",
       "162   39.6906   -96.1264  POINT (-96.12640 39.69060)  \n",
       "163   39.6961   -96.1486  POINT (-96.14860 39.69610)  \n",
       "164   39.7050   -96.1639  POINT (-96.16390 39.70500)  \n",
       "\n",
       "[165 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/content')\n",
    "from src.fluvius import USGS_Water_DB\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "db = USGS_Water_DB()\n",
    "db.get_station_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963f7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--log-level=OFF')\n",
    "    driver = webdriver.Chrome(ChromeDriverManager(print_first_line=False).install(), options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def get_url_text(driver, url, verbose=False):\n",
    "    driver.get(url)\n",
    "    result = requests.get(url, allow_redirects=False)\n",
    "    if result.status_code==200:\n",
    "        if verbose:\n",
    "            print('Data found!')\n",
    "        soup = bs(result.text, 'html.parser') \n",
    "        return soup\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('Data does not exist')\n",
    "        return None\n",
    "        \n",
    "def get_marker_info(marker_text, return_geodataframe=True):\n",
    "    site_no = marker_text.split('site_no=')[1].split('>')[0].replace('\"','')\n",
    "    point = [float(p) for p in marker_text.split('[')[1].split(']')[0].split(',')]\n",
    "    lat = point[0]\n",
    "    lon = point[1]\n",
    "    site_name = marker_text.split('<hr>')[1].split('<br')[0]\n",
    "    df = pd.DataFrame([{'site_no':site_no,'site_name':site_name,'Latitude':lat,'Longitude':lon}])\n",
    "    if return_geodataframe:\n",
    "        return gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude,df.Latitude))\n",
    "    return df\n",
    "\n",
    "def get_station_df(driver=None):\n",
    "    if driver is None:\n",
    "        driver = create_driver()\n",
    "    #need to get the metadata for the site too...\n",
    "    site_url = 'https://nrtwq.usgs.gov'\n",
    "    soup = get_url_text(driver, site_url)\n",
    "    js = str(soup.findAll('script')[6])\n",
    "    marker_text_raw = js.split('L.marker')[1:-1]\n",
    "    marker_df = pd.concat([get_marker_info(m) for m in marker_text_raw]).reset_index(drop=True)\n",
    "    #error here with reindexing...\n",
    "    return marker_df\n",
    "\n",
    "def process_soup(soup):\n",
    "    data_raw = str(soup).split('\\n')\n",
    "    data_raw = [elem for elem in data_raw if not ('#' in elem)]\n",
    "    data_split = [d.split('\\t') for d in data_raw]\n",
    "    y = (i for i,v in enumerate(data_split) if ('' in v))\n",
    "    stop = next(y) #identify end of the string of continuous data\n",
    "    cols = data_split[0]\n",
    "    units = data_split[1]\n",
    "    columns = [f'{c} ({u})' if ' ' not in u else f'{c}' for c,u in zip(cols,units) ]\n",
    "    data = data_split[2:stop]\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "\n",
    "def get_water_url(site_no, attribute, year):\n",
    "    pcode_list = {'discharge':'00060',\\\n",
    "          'turbidity':'63680',\\\n",
    "          'temperature':'00010',\\\n",
    "          'dissolved_oxygen':'00300',\\\n",
    "          'ssd':'99409'}\n",
    "    url_header = 'https://nrtwq.usgs.gov/explore/datatable?'\n",
    "    timestep = 'uv'\n",
    "    period = f'{year}_all'\n",
    "    l = {'url_header':url_header, 'site_no':site_no, 'timestep':timestep}\n",
    "    l['period'] = period\n",
    "    l['pcode'] = pcode_list[attribute]\n",
    "    url = f\"{l['url_header']}site_no={l['site_no']}&pcode={l['pcode']}&period={l['period']}&timestep={l['timestep']}&format=rdb&is_verbose=y\"\n",
    "    return url\n",
    " \n",
    "def get_water_attribute(driver, site_no, attribute, year):\n",
    "    water_url = get_water_url(site_no, attribute, year)\n",
    "    textsoup = get_url_text(driver, water_url, verbose=False)\n",
    "    out = None\n",
    "    if textsoup is not None:\n",
    "        out = process_soup(textsoup)\n",
    "    return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9ceddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 90.0.4430\n",
      "[WDM] - Get LATEST driver version for 90.0.4430\n",
      "[WDM] - There is no [linux64] chromedriver for browser 90.0.4430 in cache\n",
      "[WDM] - Get LATEST driver version for 90.0.4430\n",
      "[WDM] - Trying to download new driver from https://chromedriver.storage.googleapis.com/90.0.4430.24/chromedriver_linux64.zip\n",
      "[WDM] - Driver has been saved in cache [/root/.wdm/drivers/chromedriver/linux64/90.0.4430.24]\n"
     ]
    }
   ],
   "source": [
    "driver = create_driver()\n",
    "df = get_station_df(driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a3a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/content/data/station_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9df1397a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07144000'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.site_no[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#things to consider \n",
    "# year, maybe check the years first?\n",
    "# pcode variables...\n",
    "# we can find out if everything has discharge and if everything has turbidity?\n",
    "# let's acquire the data one by one for the years available\n",
    "# define a function to get a specific pcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1234af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed out for 07144000, year 2013!\n",
      "Timed out for 07144000, year 2014!\n",
      "Timed out for 07144000, year 2015!\n",
      "Timed out for 07144000, year 2016!\n",
      "Timed out for 07144000, year 2017!\n",
      "Timed out for 07144000, year 2018!\n",
      "Timed out for 07144000, year 2019!\n",
      "Timed out for 07144000, year 2020!\n",
      "Timed out for 07144000, year 2021!\n",
      "Timed out for 07144100, year 2021!\n",
      "Wrote /content/data/07144100_data.csv!\n",
      "Timed out for 07144200, year 2013!\n",
      "Timed out for 07144200, year 2014!\n",
      "Timed out for 07144200, year 2015!\n",
      "Timed out for 07144200, year 2016!\n",
      "Timed out for 07144200, year 2017!\n",
      "Timed out for 07144200, year 2018!\n",
      "Timed out for 07144200, year 2019!\n",
      "Timed out for 07144200, year 2020!\n",
      "Timed out for 07144200, year 2021!\n",
      "Timed out for 07144780, year 2013!\n",
      "Timed out for 07144780, year 2014!\n",
      "Timed out for 07144780, year 2015!\n",
      "Timed out for 07144780, year 2016!\n",
      "Timed out for 07144780, year 2017!\n",
      "Timed out for 07144780, year 2018!\n",
      "Timed out for 07144780, year 2019!\n",
      "Timed out for 07144780, year 2020!\n",
      "Timed out for 07144780, year 2021!\n",
      "Timed out for 07144790, year 2013!\n",
      "Timed out for 07144790, year 2014!\n",
      "Timed out for 07144790, year 2015!\n",
      "Timed out for 07144790, year 2016!\n",
      "Timed out for 07144790, year 2017!\n",
      "Timed out for 07144790, year 2018!\n",
      "Timed out for 07144790, year 2019!\n",
      "Timed out for 07144790, year 2020!\n",
      "Timed out for 07144790, year 2021!\n",
      "Timed out for 07146500, year 2013!\n",
      "Timed out for 07146500, year 2014!\n",
      "Timed out for 07146500, year 2015!\n",
      "Timed out for 07146500, year 2016!\n",
      "Timed out for 07146500, year 2017!\n",
      "Timed out for 07146500, year 2018!\n",
      "Timed out for 07146500, year 2019!\n",
      "Timed out for 07146500, year 2020!\n",
      "Timed out for 07146500, year 2021!\n",
      "Timed out for 07147800, year 2013!\n",
      "Timed out for 07147800, year 2014!\n",
      "Timed out for 07147800, year 2015!\n",
      "Timed out for 07147800, year 2016!\n",
      "Timed out for 07147800, year 2017!\n",
      "Timed out for 07147800, year 2018!\n",
      "Timed out for 07147800, year 2019!\n",
      "Timed out for 07147800, year 2020!\n",
      "Timed out for 07147800, year 2021!\n",
      "Timed out for 07169800, year 2013!\n",
      "Timed out for 07169800, year 2014!\n",
      "Timed out for 07169800, year 2015!\n",
      "Timed out for 07169800, year 2016!\n",
      "Timed out for 07169800, year 2017!\n",
      "Timed out for 07169800, year 2018!\n",
      "Timed out for 07169800, year 2019!\n",
      "Timed out for 07169800, year 2020!\n",
      "Timed out for 07169800, year 2021!\n",
      "Timed out for 07179750, year 2013!\n",
      "Timed out for 07179750, year 2014!\n",
      "Timed out for 07179750, year 2021!\n",
      "Wrote /content/data/07179750_data.csv!\n",
      "Timed out for 07182250, year 2013!\n",
      "Timed out for 07182250, year 2014!\n",
      "Timed out for 07182250, year 2021!\n",
      "Wrote /content/data/07182250_data.csv!\n",
      "Timed out for 07182280, year 2013!\n",
      "Timed out for 07182280, year 2014!\n",
      "Timed out for 07182280, year 2015!\n",
      "Timed out for 07182280, year 2016!\n",
      "Timed out for 07182280, year 2017!\n",
      "Timed out for 07182280, year 2018!\n",
      "Timed out for 07182280, year 2019!\n",
      "Timed out for 07182280, year 2020!\n",
      "Timed out for 07182280, year 2021!\n",
      "Timed out for 07182390, year 2013!\n"
     ]
    }
   ],
   "source": [
    "#with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#    for site_no, out in zip(df.site_no, executor.map(get_attribute_years, df.site_no)):\n",
    "#        site_meta.append({'site_no':site_no,\\\n",
    "#                          'ssd_record_years':out[0],\\\n",
    "#                          'discharge_record_years':out[1]})\n",
    "\n",
    "for site_no in df.site_no[80:]:\n",
    "    d = []\n",
    "    for year in np.arange(2013, 2022):\n",
    "        try:\n",
    "            time.sleep(10)\n",
    "            ssd_df = get_water_attribute(driver, site_no, 'ssd', year)\n",
    "            time.sleep(10)\n",
    "            d_df = get_water_attribute(driver, site_no, 'discharge', year)\n",
    "            merged = d_df.merge(ssd_df, on='Date-Time')\n",
    "            if d_df is not None:\n",
    "                d.append(merged)\n",
    "        except:\n",
    "            print(f'Timed out for {site_no}, year {year}!')\n",
    "            continue #could time out due to no data available\n",
    "    if d:\n",
    "        a_df = pd.concat(d).dropna()\n",
    "        sitefile = f'/content/data/{site_no}_data.csv' \n",
    "        a_df.to_csv(sitefile, index=False)\n",
    "        print(f'Wrote {sitefile}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f851d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have this list, we have a list of urls that we can use. \n",
    "#start concatenating data into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc518cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class USGS_Water_Data:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.driver = create_driver()\n",
    "    def create_driver(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument('--headless')\n",
    "        chrome_options.add_argument('--no-sandbox')\n",
    "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        self.driver = webdriver.Chrome(ChromeDriverManager().install(), options=chrome_options)\n",
    "    def get_data(self):\n",
    "        pass\n",
    "    def process_soup(soup):\n",
    "        data_raw = str(soup).split('\\n')\n",
    "        data_raw = [elem for elem in data_raw if not ('#' in elem)]\n",
    "        data_split = [d.split('\\t') for d in data_raw]\n",
    "        y = (i for i,v in enumerate(data_split) if ('' in v))\n",
    "        stop = next(y)\n",
    "        cols = data_split[0]\n",
    "        units = data_split[1]\n",
    "        columns = [f'{c} ({u})' if ' ' not in u else f'{c}' for c,u in zip(cols,units) ]\n",
    "        data = data_split[2:stop]\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "        return df\n",
    "    def get_marker_info(marker_text, return_geodataframe=True):\n",
    "        site_no = marker_text.split('site_no=')[1].split('>')[0].replace('\"','')\n",
    "        point = [float(p) for p in marker_text.split('[')[1].split(']')[0].split(',')]\n",
    "        lat = point[0]\n",
    "        lon = point[1]\n",
    "        site_name = marker_text.split('<hr>')[1].split('<br')[0]\n",
    "        df = pd.DataFrame([{'site_no':site_no,'site_name':site_name,'Latitude':lat,'Longitude':lon}])\n",
    "        if return_geodataframe:\n",
    "            return gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude,df.Latitude))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b032af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
