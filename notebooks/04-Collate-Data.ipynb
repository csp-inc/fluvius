{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245ffb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Environment setup\n",
    "import sys\n",
    "sys.path.append('/content')\n",
    "from src.fluvius import WaterData, WaterStation\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import fsspec\n",
    "from pystac_client import Client\n",
    "import planetary_computer as pc\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Set the environment variable PC_SDK_SUBSCRIPTION_KEY, or set it here.\n",
    "# The Hub sets PC_SDK_SUBSCRIPTION_KEY automatically.\n",
    "# pc.settings.set_subscription_key(<YOUR API Key>)\n",
    "env_vars = !cat /content/.env\n",
    "\n",
    "for var in env_vars:\n",
    "    key, value = var.split(' = ')\n",
    "    os.environ[key] = value\n",
    "\n",
    "#################  set up ####################\n",
    "data_source = 'itv'\n",
    "container = f'{data_source}-data'\n",
    "\n",
    "storage_options={'account_name':os.environ['ACCOUNT_NAME'],\\\n",
    "                 'account_key':os.environ['BLOB_KEY']}\n",
    "fs = fsspec.filesystem('az',\\\n",
    "                       account_name=storage_options['account_name'],\\\n",
    "                       account_key=storage_options['account_key'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54ade9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def datestdtojd (stddate):\n",
    "    fmt='%Y-%m-%d'\n",
    "    sdtdate = datetime.datetime.strptime(stddate, fmt)\n",
    "    sdtdate = sdtdate.timetuple()\n",
    "    jdate = sdtdate.tm_yday\n",
    "    return(jdate)\n",
    "\n",
    "def process_df(df, datatype):\n",
    "    df = df.copy()\n",
    "    if datatype == 'ana':\n",
    "        df = df.rename(columns={'Suspended Sediment Concentration (mg/L)':'SSC (mg/L)',\\\n",
    "                           'Discharge': 'Q (m3/s)'})\n",
    "    elif datatype == 'itv':\n",
    "        df = df.rename(columns={'SSC (mg/l)':'SSC (mg/L)',\\\n",
    "                           'Q (mÂ³/s)': 'Q (m3/s)'})\n",
    "    elif datatype == 'usgs':\n",
    "        df = df.rename(columns={'Computed instantaneous suspended sediment (mg/L)':'SSC (mg/L)',\\\n",
    "                           'Instantaneous computed discharge (cfs)': 'Q (m3/s)'})\n",
    "        cfs_to_m3s = 0.028316847\n",
    "        df['Q (m3/s)'] = cfs_to_m3s * df['Q (m3/s)']\n",
    "    else:\n",
    "        df = df.rename(columns={'Instantaneous suspended sediment (mg/L)':'SSC (mg/L)',\\\n",
    "                           'Instantaneous computed discharge (cfs)': 'Q (m3/s)'})\n",
    "        cfs_to_m3s = 0.028316847\n",
    "        df['Q (m3/s)'] = cfs_to_m3s * df['Q (m3/s)']\n",
    "        \n",
    "    df['julian'] = [datestdtojd(d) for d in df['Date-Time']]\n",
    "    selection = ['region', 'site_no', 'sample_id','julian',\\\n",
    "                 'Date-Time', 'Q (m3/s)', 'SSC (mg/L)',\\\n",
    "                 'Chip Cloud Pct','sentinel-2-l2a_R','sentinel-2-l2a_G','sentinel-2-l2a_B']\n",
    "    return df[selection]\n",
    "    \n",
    "container_list = ['ana', 'itv', 'usgsi', 'usgs']\n",
    "#we are looking for all the individual processed csv\n",
    "#adding a column for the data type\n",
    "db = []\n",
    "for con in container_list:\n",
    "    f = fs.walk(f'{con}-data/stations')\n",
    "    processed_list = []\n",
    "    for a in f:\n",
    "        for b in a:\n",
    "            for c in b:\n",
    "                if 'processed' in c:\n",
    "                    file = f'az://{a[0]}/{c}'\n",
    "                    processed_list.append(pd.read_csv(file, storage_options=storage_options))\n",
    "    df = pd.concat(processed_list)\n",
    "    df.insert(0,'site_no',[i[:8] for i in df.sample_id])\n",
    "    df.insert(0,'region',con)\n",
    "    db.append(process_df(df, con))\n",
    "db = pd.concat(db).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "504d9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db.to_json('az://modeling-data/fluvius_data.json',storage_options=storage_options)\n",
    "db.to_csv('az://modeling-data/fluvius_data.csv',\\\n",
    "          index=False,\\\n",
    "          storage_options=storage_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
