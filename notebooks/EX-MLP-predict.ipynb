{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/content\")\n",
    "from src.utils import fit_mlp, plot_obs_predict\n",
    "\n",
    "with open(\"/content/credentials\") as f:\n",
    "    env_vars = f.read().split(\"\\n\")\n",
    "\n",
    "for var in env_vars:\n",
    "    key, value = var.split(\" = \")\n",
    "    os.environ[key] = value\n",
    "\n",
    "storage_options = {\"account_name\":os.environ[\"ACCOUNT_NAME\"],\n",
    "                   \"account_key\":os.environ[\"BLOB_KEY\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters and fit model\n",
    "buffer_distance = 500\n",
    "day_tolerance = 8\n",
    "cloud_thr = 80\n",
    "min_water_pixels = 20\n",
    "features = [\n",
    "    \"Intercept\", \"sentinel-2-l2a_AOT\", \n",
    "    \"sentinel-2-l2a_B02\", \"sentinel-2-l2a_B03\", \"sentinel-2-l2a_B04\", # RGB bands\n",
    "    \"sentinel-2-l2a_B08\", # NIR\n",
    "    #\"sentinel-2-l2a_WVP\", \n",
    "    \"sentinel-2-l2a_B05\", \"sentinel-2-l2a_B06\", \"sentinel-2-l2a_B07\", \"sentinel-2-l2a_B8A\",  # Red edge bands\n",
    "    \"is_brazil\", #\"sine_julian\", \n",
    "    \"sentinel-2-l2a_B11\", \"sentinel-2-l2a_B12\", # SWIR\n",
    "    \"mean_viewing_azimuth\", \"mean_viewing_zenith\",\n",
    "    \"mean_solar_azimuth\", \"mean_solar_zenith\"\n",
    "]\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "learning_rate = 0.005\n",
    "\n",
    "layer_out_neurons = [12, 24, 6]\n",
    "n_layers = len(layer_out_neurons)\n",
    "\n",
    "model_out = fit_mlp(\n",
    "    features,\n",
    "    learning_rate,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    storage_options,\n",
    "    buffer_distance=buffer_distance,\n",
    "    day_tolerance=day_tolerance,\n",
    "    cloud_thr=cloud_thr,\n",
    "    mask_method1=\"lulc\",\n",
    "    mask_method2=\"ndvi\",\n",
    "    min_water_pixels=min_water_pixels,\n",
    "    layer_out_neurons=layer_out_neurons\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed vs predicted for Test data\n",
    "plot_obs_predict(\n",
    "    model_out[\"val_obs_predict\"],\n",
    "    title=\"Predicted vs. Observed for Withheld Validation Data\",\n",
    "    savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed vs predicted for Train data\n",
    "plot_obs_predict(\n",
    "    model_out[\"train_obs_predict\"],\n",
    "    title=\"Predicted vs. Observed for Training Data\",\n",
    "    savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed vs predicted for ITV data\n",
    "plot_obs_predict(\n",
    "    model_out[\"itv_obs_predict\"],\n",
    "    title=\"Predicted vs. Observed for ITV Data\",\n",
    "    savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_out[\"train_R2\"])\n",
    "print(model_out[\"val_R2\"])\n",
    "print(model_out[\"itv_R2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make pixel-level predictions\n",
    "import pandas as pd, numpy as np, rasterio as rio\n",
    "fp = f\"az://modeling-data/partitioned_feature_data_buffer500m_daytol8_cloudthr80percent_lulcndvi_masking.csv\"\n",
    "data = pd.read_csv(fp, storage_options=storage_options)\n",
    "\n",
    "not_enough_water = data[\"n_water_pixels\"] <= min_water_pixels\n",
    "data.drop(not_enough_water[not_enough_water].index, inplace=True)\n",
    "data[\"Log SSC (mg/L)\"] = np.log(data[\"SSC (mg/L)\"])\n",
    "\n",
    "lnssc_0 = data[\"Log SSC (mg/L)\"] == 0\n",
    "data.drop(lnssc_0[lnssc_0].index, inplace=True)\n",
    "\n",
    "sentinel_features = [x for x in features if \"sentinel\" in x]\n",
    "non_sentinel_features = [x for x in features if \"sentinel\" not in x]\n",
    "observation = data.reset_index().loc[list(data[\"sample_id\"]).index(\"0000ITV6_00000017\"), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIO_BANDS_ORDERED = {\n",
    "    \"sentinel-2-l2a_AOT\":1, \n",
    "    \"sentinel-2-l2a_B02\":2, \n",
    "    \"sentinel-2-l2a_B03\":3, \n",
    "    \"sentinel-2-l2a_B04\":4, \n",
    "    \"sentinel-2-l2a_B08\":5, \n",
    "    \"sentinel-2-l2a_WVP\":6,\n",
    "    \"sentinel-2-l2a_B05\":7, \n",
    "    \"sentinel-2-l2a_B06\":8, \n",
    "    \"sentinel-2-l2a_B07\":9, \n",
    "    \"sentinel-2-l2a_B8A\":10, \n",
    "    \"sentinel-2-l2a_B11\":11, \n",
    "    \"sentinel-2-l2a_B12\":12\n",
    "}\n",
    "\n",
    "with rio.Env(\n",
    "    AZURE_STORAGE_ACCOUNT=os.environ[\"ACCOUNT_NAME\"], \n",
    "    AZURE_STORAGE_ACCESS_KEY=os.environ[\"BLOB_KEY\"]\n",
    "):\n",
    "    with rio.open(observation[\"raw_img_chip_href\"]) as ds:\n",
    "        img = ds.read([RIO_BANDS_ORDERED[x] for x in sentinel_features])\n",
    "    with rio.open(observation[\"water_chip_href\"]) as ds:\n",
    "        water = ds.read(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_sentinel_values = list(observation[non_sentinel_features[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def predict_pixel_ssc(sentinel_values, sentinel_features, non_sentinel_values, non_sentinel_features, all_features, scaler, model):\n",
    "    obs_dict = dict.fromkeys(all_features)\n",
    "    obs_dict.update(zip(sentinel_features, sentinel_values))\n",
    "    obs_dict.update(zip(non_sentinel_features, [1] + non_sentinel_values))\n",
    "    feature_values = torch.Tensor(\n",
    "        list(\n",
    "            scaler.transform(\n",
    "                np.array(\n",
    "                    list(obs_dict.values()), ndmin=2\n",
    "                    )\n",
    "                )[0, :]\n",
    "            )\n",
    "        )\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y_pred = model(feature_values).squeeze().numpy()\n",
    "\n",
    "    return np.exp(y_pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.empty(water.shape)\n",
    "predictions[(water == False)] = np.NaN\n",
    "predictions[(water == True)] = np.apply_along_axis(predict_pixel_ssc, 0, img[:, (water == True)], sentinel_features, non_sentinel_values, non_sentinel_features, features, model_out[\"scaler\"], model_out[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "cm = plt.get_cmap('hot')\n",
    "\n",
    "ssc = (cm(np.interp(predictions, (np.nanmin(predictions), np.nanmax(predictions)), (0, 1))) * 255).astype(np.uint8)[:,:, 0:3]\n",
    "mean_pred = np.nanmean(predictions)\n",
    "observed = observation[\"Log SSC (mg/L)\"]\n",
    "\n",
    "img2 =  np.moveaxis(\n",
    "    np.interp(\n",
    "        np.clip(\n",
    "            img[[3,2,1], :, :], \n",
    "            0,\n",
    "            6000\n",
    "        ), \n",
    "        (0, 6000),\n",
    "        (0, 1)\n",
    "    ) ** 0.6 * 255,\n",
    "    0,\n",
    "    2\n",
    ").astype(np.uint8)\n",
    "\n",
    "img2[(water == True), :] = ssc[(water == True), :]\n",
    "\n",
    "img2_pil = Image.fromarray(img2)\n",
    "img2_pil.resize((512, 512), Image.NEAREST).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.nanmin(predictions), np.nanmax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
